{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54ce62cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Import all models\n",
    "from resnet import ResNet18, ResidualBlock\n",
    "from mobilenet import MobileNetV1, MobileNetV2\n",
    "from vggnet import VGG16\n",
    "from data import ImgDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81344bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353b38d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base paths (adjusted to relative or specific paths as needed)\n",
    "# Ensure these point to where 'preprocess.py' saved the data\n",
    "BASE_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"Dataset\", \"plantvillage dataset\")\n",
    "CSV_PATH = os.path.join(DATA_DIR, \"dataframes\")\n",
    "TRAIN_IMG = os.path.join(DATA_DIR, \"train\")\n",
    "VAL_IMG = os.path.join(DATA_DIR, \"val\")\n",
    "TEST_IMG = os.path.join(DATA_DIR, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c70ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = os.path.join(CSV_PATH, \"train_labels.csv\")\n",
    "val_csv_path = os.path.join(CSV_PATH, \"val_labels.csv\")\n",
    "test_csv_path = os.path.join(CSV_PATH, \"test_labels.csv\")\n",
    "\n",
    "print(f\"Path to training CSV: {train_csv_path}\")\n",
    "print(f\"Path to validation CSV: {val_csv_path}\")\n",
    "print(f\"Path to test CSV: {test_csv_path}\")\n",
    "\n",
    "train_csv = pandas.read_csv(train_csv_path)\n",
    "val_csv = pandas.read_csv(val_csv_path)\n",
    "test_csv = pandas.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c5f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "mild_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomVerticalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(*stats)\n",
    "])\n",
    "\n",
    "moderate_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomVerticalFlip(),\n",
    "    T.RandomRotation(90),\n",
    "    T.RandomResizedCrop(256, scale=(0.8, 1.0)),\n",
    "    T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.02),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(*stats)\n",
    "])\n",
    "\n",
    "aggressive_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomVerticalFlip(),\n",
    "    T.RandomRotation(180),\n",
    "    T.RandomResizedCrop(256, scale=(0.3, 1.0)),\n",
    "    T.ColorJitter(brightness=0.6, contrast=0.6, saturation=0.6, hue=0.03),\n",
    "    T.RandomApply([T.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0))], p=0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(*stats)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9e0675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = ImgDataset(val_csv, VAL_IMG, transform=mild_transform)\n",
    "test_ds = ImgDataset(test_csv, TEST_IMG, transform=mild_transform)\n",
    "\n",
    "num_train = len(train_csv)\n",
    "mild_end = int(0.6 * num_train)\n",
    "moderate_end = int(0.9 * num_train)\n",
    "\n",
    "train_ds_mild = ImgDataset(train_csv.iloc[:mild_end], TRAIN_IMG, transform=mild_transform)\n",
    "train_ds_moderate = ImgDataset(train_csv.iloc[mild_end:moderate_end], TRAIN_IMG, transform=moderate_transform)\n",
    "train_ds_aggressive = ImgDataset(train_csv.iloc[moderate_end:], TRAIN_IMG, transform=aggressive_transform)\n",
    "\n",
    "train_ds = torch.utils.data.ConcatDataset([train_ds_mild, train_ds_moderate, train_ds_aggressive])\n",
    "\n",
    "num_classes = len(train_ds_mild.classes)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(train_ds_mild.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a56bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Params\n",
    "batch_size = 32\n",
    "lr = 2e-4\n",
    "weight_decay = 1e-3\n",
    "MODEL_DIR = \"../models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1 & 2. CONFIGURATION FOR ALL MODELS\n",
    "# Each model has its own Epochs and Early Stopping Patience\n",
    "# ---------------------------------------------------------\n",
    "model_configs = [\n",
    "    {\n",
    "        \"name\": \"ResNet18\",\n",
    "        \"model\": ResNet18(block=ResidualBlock, blocks_per_layer=[2, 2, 2, 2], n_channels=3, n_classes=num_classes),\n",
    "        \"epochs\": 15,\n",
    "        \"patience\": 5\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"MobileNetV1\",\n",
    "        \"model\": MobileNetV1(n_channels=3, n_classes=num_classes),\n",
    "        \"epochs\": 20,  # Light models often need longer to converge\n",
    "        \"patience\": 7\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"MobileNetV2\",\n",
    "        \"model\": MobileNetV2(n_channels=3, n_classes=num_classes),\n",
    "        \"epochs\": 20,\n",
    "        \"patience\": 7\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"VGG16\",\n",
    "        \"model\": VGG16(n_channels=3, n_classes=num_classes),\n",
    "        \"epochs\": 15,\n",
    "        \"patience\": 5\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9a0ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Helper Function: Train and Evaluate with Early Stopping & F1\n",
    "# ---------------------------------------------------------\n",
    "def train_and_evaluate(config):\n",
    "    name = config[\"name\"]\n",
    "    model = config[\"model\"].to(device)\n",
    "    num_epochs = config[\"epochs\"]\n",
    "    patience = config[\"patience\"]\n",
    "    \n",
    "    print(f\"\\n{'='*40}\\nTraining {name}\\n{'='*40}\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # --- TRAINING ---\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_acc = correct / total * 100\n",
    "        \n",
    "        # --- VALIDATION (Accuracy + F1 Score) ---\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0, 0, 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = correct / total * 100\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        \n",
    "        print(f\"Results: Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"         Train Acc:  {train_acc:.2f}%   | Val Acc:  {val_acc:.2f}%\")\n",
    "        print(f\"                                     | Val F1:   {val_f1:.4f}\")\n",
    "        \n",
    "        # --- EARLY STOPPING CHECK ---\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            epochs_no_improve = 0\n",
    "            save_path = os.path.join(MODEL_DIR, f\"{name}_best.pth\")\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"--> Best model saved to {save_path}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"--> No improvement for {epochs_no_improve}/{patience} epochs.\")\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"--> Early stopping triggered for {name}!\")\n",
    "                break\n",
    "    \n",
    "    return best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21eb736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Main Execution Loop\n",
    "# ---------------------------------------------------------\n",
    "results = {}\n",
    "\n",
    "for config in model_configs:\n",
    "    best_acc = train_and_evaluate(config)\n",
    "    results[config[\"name\"]] = best_acc\n",
    "    \n",
    "print(\"\\nFinal Best Validation Accuracies:\")\n",
    "for name, acc in results.items():\n",
    "    print(f\"{name}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2eccf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 4. MODEL SIZE & PARAMETER COUNT\n",
    "# ---------------------------------------------------------\n",
    "def get_model_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    return size_all_mb\n",
    "\n",
    "print(f\"{'Model':<15} | {'Params (M)':<12} | {'Size (MB)':<10}\")\n",
    "print(\"-\"*45)\n",
    "\n",
    "for config in model_configs:\n",
    "    model = config[\"model\"]\n",
    "    # Move to CPU for static calculation just in case\n",
    "    model.cpu()\n",
    "    \n",
    "    num_params = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "    size_mb = get_model_size(model)\n",
    "    \n",
    "    print(f\"{config['name']:<15} | {num_params:<12.2f} | {size_mb:<10.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-markdown",
   "metadata": {},
   "source": [
    "# 3. Should I prioritize Accuracy or F1 Score?\n",
    "\n",
    "**Short Answer:** For the PlantVillage dataset (which has class imbalance), you should prioritize **F1 Score**.\n",
    "\n",
    "**Detailed Explanation:**\n",
    "1.  **Accuracy** simply measures the percentage of correct predictions. If your dataset is imbalanced (e.g., 90% \"Healthy\" and 10% \"Rot\"), a model that blindly guesses \"Healthy\" for everything will get 90% Accuracy but is completely useless for disease detection.\n",
    "2.  **F1 Score** is the harmonic mean of Precision and Recall. It penalizes the model if it fails to detect the minority classes (diseases) or generates too many false alarms. \n",
    "3.  **Context:** In agriculture, False Negatives (missing a disease) are dangerous. F1 Score gives you a much more honest picture of how well the model is actually identifying the specific diseases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
