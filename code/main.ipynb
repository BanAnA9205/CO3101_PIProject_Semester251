{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54ce62cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from resnet import ResNet18, ResidualBlock\n",
    "from data import ImgDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81344bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c70ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to training CSV: /home/banana9205/Desktop/Main/Uni/DATH/Dataset/plantvillage dataset/dataframes/train_labels.csv\n",
      "Path to validation CSV: /home/banana9205/Desktop/Main/Uni/DATH/Dataset/plantvillage dataset/dataframes/val_labels.csv\n",
      "Path to test CSV: /home/banana9205/Desktop/Main/Uni/DATH/Dataset/plantvillage dataset/dataframes/test_labels.csv\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = \"/home/banana9205/Desktop/Main/Uni/DATH/Dataset/plantvillage dataset/dataframes\"\n",
    "train_csv_path = os.path.join(CSV_PATH, \"train_labels.csv\")\n",
    "val_csv_path = os.path.join(CSV_PATH, \"val_labels.csv\")\n",
    "test_csv_path = os.path.join(CSV_PATH, \"test_labels.csv\")\n",
    "\n",
    "print(f\"Path to training CSV: {train_csv_path}\")\n",
    "print(f\"Path to validation CSV: {val_csv_path}\")\n",
    "print(f\"Path to test CSV: {test_csv_path}\")\n",
    "\n",
    "train_csv = pandas.read_csv(train_csv_path)\n",
    "val_csv = pandas.read_csv(val_csv_path)\n",
    "test_csv = pandas.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e0675c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 15\n",
      "         plant                             disease\n",
      "0        Apple                          Apple_scab\n",
      "1        Apple                           Black_rot\n",
      "2        Apple                    Cedar_apple_rust\n",
      "3        Apple                             healthy\n",
      "4        Grape                           Black_rot\n",
      "5        Grape                Esca_(Black_Measles)\n",
      "6        Grape  Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "7        Grape                             healthy\n",
      "8        Peach                      Bacterial_spot\n",
      "9        Peach                             healthy\n",
      "10      Potato                        Early_blight\n",
      "11      Potato                         Late_blight\n",
      "12      Potato                             healthy\n",
      "13  Strawberry                         Leaf_scorch\n",
      "14  Strawberry                             healthy\n"
     ]
    }
   ],
   "source": [
    "IMG_PATH = \"/home/banana9205/Desktop/Main/Uni/DATH/Dataset/plantvillage dataset\"\n",
    "TRAIN_IMG = os.path.join(IMG_PATH, \"train\")\n",
    "VAL_IMG = os.path.join(IMG_PATH, \"val\")\n",
    "TEST_IMG = os.path.join(IMG_PATH, \"test\")\n",
    "\n",
    "# Augmentation\n",
    "transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomVerticalFlip(),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "train_ds = ImgDataset(train_csv, TRAIN_IMG, transform = transform)\n",
    "val_ds = ImgDataset(val_csv, VAL_IMG)\n",
    "test_ds = ImgDataset(test_csv, TEST_IMG)\n",
    "\n",
    "num_classes = len(train_ds.classes)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(train_ds.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a56bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training params\n",
    "batch_size = 32\n",
    "lr = 2e-4\n",
    "weight_decay = 1e-3\n",
    "num_epochs = 10\n",
    "img_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9a0ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.join(\"/home/banana9205/Desktop/Main/Uni/DATH/models\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "model = ResNet18(block = ResidualBlock,\n",
    "                 blocks_per_layer = [2, 2, 2, 2],\n",
    "                 n_channels = 3,\n",
    "                 n_classes = num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), \n",
    "                        lr = lr,\n",
    "                        weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21eb736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 298/298 [00:46<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8925, Train Acc: 70.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 64/64 [00:03<00:00, 18.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.7948, Val Acc: 73.13%\n",
      "Best model saved.\n",
      "\n",
      "Epoch [2/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 298/298 [00:50<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4310, Train Acc: 85.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 64/64 [00:03<00:00, 18.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.9139, Val Acc: 71.96%\n",
      "\n",
      "Epoch [3/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 298/298 [00:49<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2663, Train Acc: 91.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 64/64 [00:03<00:00, 17.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3224, Val Acc: 88.57%\n",
      "Best model saved.\n",
      "\n",
      "Epoch [4/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 298/298 [00:54<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2087, Train Acc: 93.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 64/64 [00:03<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2140, Val Acc: 92.92%\n",
      "Best model saved.\n",
      "\n",
      "Epoch [5/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 298/298 [00:58<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1474, Train Acc: 95.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 64/64 [00:03<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1981, Val Acc: 93.21%\n",
      "Best model saved.\n",
      "\n",
      "Epoch [6/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 298/298 [00:58<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1216, Train Acc: 95.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 64/64 [00:03<00:00, 17.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2789, Val Acc: 91.01%\n",
      "\n",
      "Epoch [7/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 298/298 [00:58<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0943, Train Acc: 96.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 64/64 [00:06<00:00,  9.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1096, Val Acc: 96.48%\n",
      "Best model saved.\n",
      "\n",
      "Epoch [8/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 298/298 [00:59<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0869, Train Acc: 97.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 64/64 [00:03<00:00, 17.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1069, Val Acc: 95.99%\n",
      "\n",
      "Epoch [9/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 298/298 [00:58<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0763, Train Acc: 97.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 64/64 [00:06<00:00,  9.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1115, Val Acc: 96.34%\n",
      "\n",
      "Epoch [10/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 298/298 [01:00<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0832, Train Acc: 97.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 64/64 [00:03<00:00, 17.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1367, Val Acc: 95.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n",
    "    model.train()\n",
    "\n",
    "    loss, correct, total = 0, 0, 0\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        batch_loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += batch_loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = loss / len(train_loader)\n",
    "    train_acc = correct / total * 100\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "    model.eval()\n",
    "    loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            batch_loss = criterion(outputs, labels)\n",
    "\n",
    "            loss += batch_loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = loss / len(val_loader)\n",
    "    val_acc = correct / total * 100\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIR, \"best_model.pth\"))\n",
    "        print(\"Best model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2eccf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 64/64 [00:03<00:00, 17.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1082, Test Acc: 96.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"best_model.pth\")))\n",
    "model.eval()\n",
    "loss, correct, total = 0, 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        batch_loss = criterion(outputs, labels)\n",
    "\n",
    "        loss += batch_loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_loss = loss / len(test_loader)\n",
    "test_acc = correct / total * 100\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
